import logging
import os
from pathlib import Path
import threading
import time
import litellm
from docling.datamodel.base_models import InputFormat
from docling.datamodel.pipeline_options import (
    ApiVlmOptions,
    ResponseFormat,
    VlmPipelineOptions,
    AcceleratorOptions,
)
from docling.document_converter import DocumentConverter, PdfFormatOption
from docling.pipeline.vlm_pipeline import VlmPipeline
import traceback
from dotenv import load_dotenv
load_dotenv()

# æœ¬åœ° Gemini API æœåŠ¡å™¨
class GeminiAPIServer:
    def __init__(self):
        self.is_running = False
        self.server_thread = None

    def start(self):
        import http.server
        import socketserver
        import json

        class CustomHandler(http.server.SimpleHTTPRequestHandler):
            def do_POST(self):
                if self.path == '/v1/chat/completions':
                    content_length = int(self.headers['Content-Length'])
                    post_data = self.rfile.read(content_length)
                    try:
                        request_data = json.loads(post_data.decode('utf-8'))
                        model = request_data.get("model", "gemini-2.5-flash-preview-05-20")
                        messages = request_data.get("messages", [])
                        response = litellm.completion(
                            model=f"gemini/{model}",
                            messages=messages,
                            temperature=request_data.get("temperature", 0.1),
                            max_tokens=request_data.get("max_tokens", 8192)
                        )
                        result = {
                            "id": response.id,
                            "object": "chat.completion",
                            "created": int(time.time()),
                            "model": model,
                            "choices": [
                                {
                                    "index": 0,
                                    "message": {
                                        "role": "assistant",
                                        "content": response.choices[0].message.content
                                    },
                                    "finish_reason": "stop"
                                }
                            ],
                            "usage": response.usage.dict() if response.usage else {}
                        }
                        self.send_response(200)
                        self.send_header('Content-type', 'application/json')
                        self.end_headers()
                        self.wfile.write(json.dumps(result).encode())
                    except Exception as e:
                        self.send_response(500)
                        self.send_header('Content-type', 'application/json')
                        self.end_headers()
                        tb = traceback.format_exc()
                        error_response = {"error": str(e), "traceback": tb}
                        self.wfile.write(json.dumps(error_response).encode())
                else:
                    self.send_response(404)
                    self.end_headers()
            def log_message(self, format, *args):
                pass

        def run_server():
            with socketserver.TCPServer(("", 4000), CustomHandler) as httpd:
                httpd.timeout = 1
                self.httpd = httpd
                while self.is_running:
                    httpd.handle_request()

        self.is_running = True
        self.server_thread = threading.Thread(target=run_server)
        self.server_thread.start()
        time.sleep(2)

    def stop(self):
        self.is_running = False
        if self.server_thread:
            self.server_thread.join(timeout=5)
        logging.info("API æœåŠ¡å™¨å·²åœæ­¢")

api_server = GeminiAPIServer()

def gemini_vlm_options(model: str, prompt: str, timeout: int = 300):
    """é…ç½® Gemini çš„ VLM é€‰é¡¹"""
    return ApiVlmOptions(
        url="http://localhost:4000/v1/chat/completions",
        params=dict(
            model=model,
            max_tokens=8192,
            temperature=0.1,
        ),
        prompt=prompt,
        timeout=timeout,
        scale=1.0,
        response_format=ResponseFormat.MARKDOWN,
    )

def process_single_pdf(pdf_path: Path, output_dir: Path, model_name: str = "gemini-2.5-flash-preview-05-20"):
    logging.info(f"æ­£åœ¨å¤„ç†: {pdf_path.name}")
    pipeline_options = VlmPipelineOptions(
        enable_remote_services=True,
        # accelerator_options=AcceleratorOptions(device="cpu", num_threads=8)  # é…ç½®deviceä¸ºcpuï¼Œçº¿ç¨‹æ•°ä¸º8
    )
    pipeline_options.vlm_options = gemini_vlm_options(
        model=model_name,
        prompt="è¯·å°†ä»¥ä¸‹æ–‡æ¡£è½¬æ¢ä¸ºMarkdownæ ¼å¼ï¼ŒåŒ…å«ï¼š1. å®Œæ•´æ–‡æœ¬å†…å®¹ 2. æ•°å­¦å…¬å¼ï¼ˆLaTeXæ ¼å¼ï¼‰ 3. å›¾è¡¨æ ‡é¢˜åŠå¼•ç”¨ 4. è¡¨æ ¼å†…å®¹ 5. å…¶ä»–é‡è¦ä¿¡æ¯",
        timeout=300
    )
    doc_converter = DocumentConverter(
        format_options={
            InputFormat.PDF: PdfFormatOption(
                pipeline_options=pipeline_options,
                pipeline_cls=VlmPipeline,
            )
        }
    )
    try:
        result = doc_converter.convert(pdf_path)
        output_file = output_dir / f"{pdf_path.stem}_content.md"
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(result.document.export_to_markdown())
        logging.info(f"è½¬æ¢å®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        return True, output_file
    except Exception as e:
        logging.error(f"å¤„ç† {pdf_path.name} æ—¶å‡ºé”™: {e}")
        return False, None

def process_pdf_folder(input_folder: str, output_folder: str = "./output", model_name: str = "gemini-2.5-flash-preview-05-20"):
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    if not os.getenv("GEMINI_API_KEY"):
        logging.error("æœªè®¾ç½® GEMINI_API_KEY ç¯å¢ƒå˜é‡")
        return
    os.environ["LITELLM_LOG"] = "ERROR"
    logging.info("=== å¯åŠ¨æœ¬åœ° API æœåŠ¡å™¨ ===")
    try:
        api_server.start()
        logging.info("API æœåŠ¡å™¨å¯åŠ¨æˆåŠŸ")
    except Exception as e:
        logging.error(f"æ— æ³•å¯åŠ¨ API æœåŠ¡å™¨: {e}")
        return
    input_path = Path(input_folder)
    if not input_path.exists():
        logging.error(f"è¾“å…¥æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {input_folder}")
        api_server.stop()
        return
    output_path = Path(output_folder)
    output_path.mkdir(parents=True, exist_ok=True)
    try:
        pdf_files = list(input_path.glob("*.pdf"))
        if not pdf_files:
            logging.warning(f"åœ¨ {input_folder} ä¸­æœªæ‰¾åˆ°PDFæ–‡ä»¶")
            return
        logging.info(f"æ‰¾åˆ° {len(pdf_files)} ä¸ªPDFæ–‡ä»¶")
        success_count = 0
        failed_files = []
        for i, pdf_file in enumerate(pdf_files, 1):
            fname_base = os.path.splitext(os.path.basename(pdf_file))[0] +  "_content.md"
            output_file = Path(os.path.join(output_path, fname_base))  # ç›®æ ‡è¾“å‡ºè·¯å¾„

            # ğŸ” æ–°å¢æ£€æŸ¥é€»è¾‘
            if output_file.exists():
                print(f"è·³è¿‡å·²å¤„ç†æ–‡ä»¶: {pdf_file} (è¾“å‡ºç›®å½•å·²å­˜åœ¨)")
                continue  # è·³è¿‡å·²å¤„ç†æ–‡ä»¶
            logging.info(f"\n=== å¤„ç†ç¬¬ {i}/{len(pdf_files)} ä¸ªæ–‡ä»¶ ===")
            success, output_file = process_single_pdf(pdf_file, output_path, model_name)
            if success:
                success_count += 1
                with open(output_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    print(f"\n--- {pdf_file.name} è½¬æ¢ç»“æœé¢„è§ˆ ---")
                    print(content[:200] + "..." if len(content) > 200 else content)
            else:
                failed_files.append(pdf_file.name)
        logging.info(f"\n=== å¤„ç†å®Œæˆ ===")
        logging.info(f"æˆåŠŸå¤„ç†: {success_count}/{len(pdf_files)} ä¸ªæ–‡ä»¶")
        if failed_files:
            logging.warning(f"å¤±è´¥æ–‡ä»¶: {', '.join(failed_files)}")
    finally:
        api_server.stop()

def main():
    input_folder = "./input"
    output_folder = "./output/Gemini"
    model_name = "gemini-2.5-flash-preview-05-20"
    # model_name = "gemini-2.5-flash-preview-04-17"
    # model_name = "gemini-2.0-flash"
    process_pdf_folder(input_folder, output_folder, model_name)

if __name__ == "__main__":
    main()